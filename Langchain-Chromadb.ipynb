{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Langchain and ChromaDB\n",
    "\n",
    "This notebook uses Langchain and ChromaDB for a simple RAG example\n",
    "\n",
    "References:\n",
    "- [What is RAG?](https://www.datacamp.com/blog/what-is-retrieval-augmented-generation-rag)\n",
    "- [What is a Vector Database?](https://learn.microsoft.com/en-us/semantic-kernel/memories/vector-db)\n",
    "- [Langchain and RAG](https://python.langchain.com/docs/use_cases/question_answering/)\n",
    "- [Langchain Document Loaders](https://python.langchain.com/docs/integrations/document_loaders/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the current data/vectordb folder\n",
    "if os.path.exists(\"data/vectordb\"):\n",
    "    os.system(\"rm -rf data/vectordb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, chunk and index the contents of the blog.\n",
    "# We only care about the post content, title and header.\n",
    "bs_strainer = bs4.SoupStrainer(class_=(\"post-content\", \"post-title\", \"post-header\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split the documents into chunks of 1000 characters with 200 characters overlap.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Model\n",
    "\n",
    "We need a different model to take care of embeddings. The following cell uses different embeddings. You need to uncomment the one you wish to use.\n",
    "The available embeddings are:\n",
    "- HuggingFace Sentence Transformer: [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2). You can pull any of the available Sentence Transformer Embeddings from https://huggingface.co/sentence-transformers\n",
    "- Ollama embedding: [nomic-embed-text](https://ollama.com/library/nomic-embed-text), [llama3](https://ollama.com/library/llama3). Ollama also provide embedding models. More information can be found at https://ollama.com/blog/embedding-models\n",
    "- GPT4All. This is a free embedding that will be downloaded when use the first time. https://python.langchain.com/docs/integrations/text_embedding/gpt4all/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/llm-test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "#from langchain_community.embeddings import OllamaEmbeddings\n",
    "#from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "\n",
    "# Index all documents in a single vector store\n",
    "# This one is using the all-MiniLM-L6-v2 model for embedding\n",
    "embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# This one is using the Ollama model for embedding, pick one of them\n",
    "# you will need to pull the model from the ollama server first\n",
    "#embedding = OllamaEmbeddings(model=\"nomic-embed-text\")  # special embedding from Ollama\n",
    "#embedding = OllamaEmbeddings(model=\"llama3:8b-instruct-q8_0\")\n",
    "\n",
    "# another open-source embedding function\n",
    "# embedding = GPT4AllEmbeddings()\n",
    "\n",
    "# Using the embeddings to index the documents in Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding, persist_directory=\"data/vectordb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model\n",
    "\n",
    "You can use any LLM for your RAG. Below are three different providers. Each provider has more than one model so you can select the model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### OLLAMA #####\n",
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama3:8b-instruct-q8_0\", temperature=0)\n",
    "\n",
    "###### OPENAI #####\n",
    "# from langchain_openai.chat_models import ChatOpenAI\n",
    "# openai_models = [\"gpt-3.5-turbo-0125\", \"gpt-4-turbo\", \"gpt-4-turbo-preview\"]\n",
    "# llm = ChatOpenAI(\n",
    "#     model_name=openai_models[0],\n",
    "#     temperature=0,\n",
    "#     api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "###### GROQ #####\n",
    "# from langchain_groq.chat_models import ChatGroq\n",
    "# groq_model = [\"mixtral-8x7b-32768\", \"gemma-7b-it\", \"llama2-70b-4096\", \"llama3-70b-8192\", \"llama3-8b-8192\"]\n",
    "# llm = ChatGroq(\n",
    "#     temperature=0,\n",
    "#     max_tokens=4096,\n",
    "#     model_name=groq_model[3], \n",
    "#     api_key = os.environ[\"GROQ_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the chain to generate a response to a question. The answer will be generated and outputted.\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Documents\n",
    "The code below shows the documents retrieved to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "rag_chain_with_source.invoke(\"What is Task Decomposition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Retriever and Ollama Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Task Decomposition?\"\n",
    "docs_result = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
      " Document(page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
      " Document(page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
      " Document(page_content='Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "pprint(docs_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Fig. 1. Overview of a LLM-powered autonomous agent system.\\n'\n",
      " 'Component One: Planning#\\n'\n",
      " 'A complicated task usually involves many steps. An agent needs to know what '\n",
      " 'they are and plan ahead.\\n'\n",
      " 'Task Decomposition#\\n'\n",
      " 'Chain of thought (CoT; Wei et al. 2022) has become a standard prompting '\n",
      " 'technique for enhancing model performance on complex tasks. The model is '\n",
      " 'instructed to “think step by step” to utilize more test-time computation to '\n",
      " 'decompose hard tasks into smaller and simpler steps. CoT transforms big '\n",
      " 'tasks into multiple manageable tasks and shed lights into an interpretation '\n",
      " 'of the model’s thinking process.\\n'\n",
      " '\\n'\n",
      " 'Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple '\n",
      " 'reasoning possibilities at each step. It first decomposes the problem into '\n",
      " 'multiple thought steps and generates multiple thoughts per step, creating a '\n",
      " 'tree structure. The search process can be BFS (breadth-first search) or DFS '\n",
      " '(depth-first search) with each state evaluated by a classifier (via a '\n",
      " 'prompt) or majority vote.\\n'\n",
      " 'Task decomposition can be done (1) by LLM with simple prompting like \"Steps '\n",
      " 'for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using '\n",
      " 'task-specific instructions; e.g. \"Write a story outline.\" for writing a '\n",
      " 'novel, or (3) with human inputs.\\n'\n",
      " '\\n'\n",
      " 'Finite context length: The restricted context capacity limits the inclusion '\n",
      " 'of historical information, detailed instructions, API call context, and '\n",
      " 'responses. The design of the system has to work with this limited '\n",
      " 'communication bandwidth, while mechanisms like self-reflection to learn from '\n",
      " 'past mistakes would benefit a lot from long or infinite context windows. '\n",
      " 'Although vector stores and retrieval can provide access to a larger '\n",
      " 'knowledge pool, their representation power is not as powerful as full '\n",
      " 'attention.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Challenges in long-term planning and task decomposition: Planning over a '\n",
      " 'lengthy history and effectively exploring the solution space remain '\n",
      " 'challenging. LLMs struggle to adjust plans when faced with unexpected '\n",
      " 'errors, making them less robust compared to humans who learn from trial and '\n",
      " 'error.\\n'\n",
      " '\\n'\n",
      " 'Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & '\n",
      " 'Labash, 2023)\\n'\n",
      " 'The heuristic function determines when the trajectory is inefficient or '\n",
      " 'contains hallucination and should be stopped. Inefficient planning refers to '\n",
      " 'trajectories that take too long without success. Hallucination is defined as '\n",
      " 'encountering a sequence of consecutive identical actions that lead to the '\n",
      " 'same observation in the environment.\\n'\n",
      " 'Self-reflection is created by showing two-shot examples to LLM and each '\n",
      " 'example is a pair of (failed trajectory, ideal reflection for guiding future '\n",
      " 'changes in the plan). Then reflections are added into the agent’s working '\n",
      " 'memory, up to three, to be used as context for querying LLM.')\n"
     ]
    }
   ],
   "source": [
    "context = format_docs(docs_result)\n",
    "pprint(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the prompt template to provide the context and question to the model.\n",
    "print(prompt)\n",
    "prompt_value = prompt.invoke(\n",
    "    {\n",
    "        \"context\": context,\n",
    "        \"question\": question\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n",
      "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: What is Task Decomposition? \n",
      "Context: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\n",
      "\n",
      "\n",
      "Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\n",
      "\n",
      "Fig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\n",
      "The heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\n",
      "Self-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM. \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "print(type(prompt_value))\n",
    "print(prompt_value.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3:8b-instruct-q8_0',\n",
       " 'created_at': '2024-04-28T23:22:23.562461Z',\n",
       " 'response': 'Task Decomposition is a technique that breaks down complex tasks into smaller and simpler steps, allowing an agent or model to plan ahead and make more manageable decisions. This can be achieved through techniques such as Chain of Thought (CoT) or Tree of Thoughts, which involve decomposing problems into multiple thought steps and generating multiple thoughts per step. Task decomposition can also be done through simple prompting, task-specific instructions, or human inputs.',\n",
       " 'done': True,\n",
       " 'context': [128006,\n",
       "  882,\n",
       "  128007,\n",
       "  198,\n",
       "  198,\n",
       "  35075,\n",
       "  25,\n",
       "  1472,\n",
       "  527,\n",
       "  459,\n",
       "  18328,\n",
       "  369,\n",
       "  3488,\n",
       "  12,\n",
       "  598,\n",
       "  86,\n",
       "  4776,\n",
       "  9256,\n",
       "  13,\n",
       "  5560,\n",
       "  279,\n",
       "  2768,\n",
       "  9863,\n",
       "  315,\n",
       "  31503,\n",
       "  2317,\n",
       "  311,\n",
       "  4320,\n",
       "  279,\n",
       "  3488,\n",
       "  13,\n",
       "  1442,\n",
       "  499,\n",
       "  1541,\n",
       "  956,\n",
       "  1440,\n",
       "  279,\n",
       "  4320,\n",
       "  11,\n",
       "  1120,\n",
       "  2019,\n",
       "  430,\n",
       "  499,\n",
       "  1541,\n",
       "  956,\n",
       "  1440,\n",
       "  13,\n",
       "  5560,\n",
       "  2380,\n",
       "  23719,\n",
       "  7340,\n",
       "  323,\n",
       "  2567,\n",
       "  279,\n",
       "  4320,\n",
       "  64694,\n",
       "  13,\n",
       "  198,\n",
       "  14924,\n",
       "  25,\n",
       "  3639,\n",
       "  374,\n",
       "  5546,\n",
       "  97478,\n",
       "  3571,\n",
       "  30,\n",
       "  220,\n",
       "  198,\n",
       "  2014,\n",
       "  25,\n",
       "  23966,\n",
       "  13,\n",
       "  220,\n",
       "  16,\n",
       "  13,\n",
       "  35907,\n",
       "  315,\n",
       "  264,\n",
       "  445,\n",
       "  11237,\n",
       "  41503,\n",
       "  39293,\n",
       "  8479,\n",
       "  1887,\n",
       "  13,\n",
       "  198,\n",
       "  2238,\n",
       "  3861,\n",
       "  25,\n",
       "  28780,\n",
       "  2,\n",
       "  198,\n",
       "  32,\n",
       "  17395,\n",
       "  3465,\n",
       "  6118,\n",
       "  18065,\n",
       "  1690,\n",
       "  7504,\n",
       "  13,\n",
       "  1556,\n",
       "  8479,\n",
       "  3966,\n",
       "  311,\n",
       "  1440,\n",
       "  1148,\n",
       "  814,\n",
       "  527,\n",
       "  323,\n",
       "  3197,\n",
       "  8469,\n",
       "  13,\n",
       "  198,\n",
       "  6396,\n",
       "  97478,\n",
       "  3571,\n",
       "  2,\n",
       "  198,\n",
       "  19368,\n",
       "  315,\n",
       "  3463,\n",
       "  320,\n",
       "  7489,\n",
       "  51,\n",
       "  26,\n",
       "  53548,\n",
       "  1880,\n",
       "  453,\n",
       "  13,\n",
       "  220,\n",
       "  508,\n",
       "  1313,\n",
       "  8,\n",
       "  706,\n",
       "  3719,\n",
       "  264,\n",
       "  5410,\n",
       "  50745,\n",
       "  15105,\n",
       "  369,\n",
       "  47594,\n",
       "  1646,\n",
       "  5178,\n",
       "  389,\n",
       "  6485,\n",
       "  9256,\n",
       "  13,\n",
       "  578,\n",
       "  1646,\n",
       "  374,\n",
       "  42075,\n",
       "  311,\n",
       "  1054,\n",
       "  27963,\n",
       "  3094,\n",
       "  555,\n",
       "  3094,\n",
       "  863,\n",
       "  311,\n",
       "  29166,\n",
       "  810,\n",
       "  1296,\n",
       "  7394,\n",
       "  35547,\n",
       "  311,\n",
       "  29602,\n",
       "  2972,\n",
       "  2653,\n",
       "  9256,\n",
       "  1139,\n",
       "  9333,\n",
       "  323,\n",
       "  35388,\n",
       "  7504,\n",
       "  13,\n",
       "  3623,\n",
       "  51,\n",
       "  29575,\n",
       "  2466,\n",
       "  9256,\n",
       "  1139,\n",
       "  5361,\n",
       "  71128,\n",
       "  9256,\n",
       "  323,\n",
       "  25351,\n",
       "  13001,\n",
       "  1139,\n",
       "  459,\n",
       "  23692,\n",
       "  315,\n",
       "  279,\n",
       "  1646,\n",
       "  753,\n",
       "  7422,\n",
       "  1920,\n",
       "  627,\n",
       "  198,\n",
       "  6670,\n",
       "  315,\n",
       "  61399,\n",
       "  320,\n",
       "  56,\n",
       "  3524,\n",
       "  1880,\n",
       "  453,\n",
       "  13,\n",
       "  220,\n",
       "  508,\n",
       "  1419,\n",
       "  8,\n",
       "  2289,\n",
       "  3623,\n",
       "  51,\n",
       "  555,\n",
       "  24919,\n",
       "  5361,\n",
       "  33811,\n",
       "  24525,\n",
       "  520,\n",
       "  1855,\n",
       "  3094,\n",
       "  13,\n",
       "  1102,\n",
       "  1176,\n",
       "  29602,\n",
       "  8449,\n",
       "  279,\n",
       "  3575,\n",
       "  1139,\n",
       "  5361,\n",
       "  3463,\n",
       "  7504,\n",
       "  323,\n",
       "  27983,\n",
       "  5361,\n",
       "  11555,\n",
       "  824,\n",
       "  3094,\n",
       "  11,\n",
       "  6968,\n",
       "  264,\n",
       "  5021,\n",
       "  6070,\n",
       "  13,\n",
       "  578,\n",
       "  2778,\n",
       "  1920,\n",
       "  649,\n",
       "  387,\n",
       "  91451,\n",
       "  320,\n",
       "  48616,\n",
       "  339,\n",
       "  38043,\n",
       "  2778,\n",
       "  8,\n",
       "  477,\n",
       "  57483,\n",
       "  320,\n",
       "  18021,\n",
       "  38043,\n",
       "  2778,\n",
       "  8,\n",
       "  449,\n",
       "  1855,\n",
       "  1614,\n",
       "  26126,\n",
       "  555,\n",
       "  264,\n",
       "  34465,\n",
       "  320,\n",
       "  20708,\n",
       "  264,\n",
       "  10137,\n",
       "  8,\n",
       "  477,\n",
       "  8857,\n",
       "  7055,\n",
       "  13,\n",
       "  198,\n",
       "  6396,\n",
       "  66266,\n",
       "  649,\n",
       "  387,\n",
       "  2884,\n",
       "  320,\n",
       "  16,\n",
       "  8,\n",
       "  555,\n",
       "  445,\n",
       "  11237,\n",
       "  449,\n",
       "  4382,\n",
       "  50745,\n",
       "  1093,\n",
       "  330,\n",
       "  35051,\n",
       "  369,\n",
       "  72189,\n",
       "  7255,\n",
       "  77,\n",
       "  16,\n",
       "  10684,\n",
       "  330,\n",
       "  3923,\n",
       "  527,\n",
       "  279,\n",
       "  1207,\n",
       "  85257,\n",
       "  369,\n",
       "  32145,\n",
       "  72189,\n",
       "  32111,\n",
       "  320,\n",
       "  17,\n",
       "  8,\n",
       "  555,\n",
       "  1701,\n",
       "  3465,\n",
       "  19440,\n",
       "  11470,\n",
       "  26,\n",
       "  384,\n",
       "  1326,\n",
       "  13,\n",
       "  330,\n",
       "  8144,\n",
       "  264,\n",
       "  3446,\n",
       "  21782,\n",
       "  1210,\n",
       "  369,\n",
       "  4477,\n",
       "  264,\n",
       "  11775,\n",
       "  11,\n",
       "  477,\n",
       "  320,\n",
       "  18,\n",
       "  8,\n",
       "  449,\n",
       "  3823,\n",
       "  11374,\n",
       "  627,\n",
       "  198,\n",
       "  77670,\n",
       "  2317,\n",
       "  3160,\n",
       "  25,\n",
       "  578,\n",
       "  22486,\n",
       "  2317,\n",
       "  8824,\n",
       "  13693,\n",
       "  279,\n",
       "  28286,\n",
       "  315,\n",
       "  13970,\n",
       "  2038,\n",
       "  11,\n",
       "  11944,\n",
       "  11470,\n",
       "  11,\n",
       "  5446,\n",
       "  1650,\n",
       "  2317,\n",
       "  11,\n",
       "  323,\n",
       "  14847,\n",
       "  13,\n",
       "  578,\n",
       "  2955,\n",
       "  315,\n",
       "  279,\n",
       "  1887,\n",
       "  706,\n",
       "  311,\n",
       "  990,\n",
       "  449,\n",
       "  420,\n",
       "  7347,\n",
       "  10758,\n",
       "  34494,\n",
       "  11,\n",
       "  1418,\n",
       "  24717,\n",
       "  1093,\n",
       "  659,\n",
       "  44107,\n",
       "  1191,\n",
       "  311,\n",
       "  4048,\n",
       "  505,\n",
       "  3347,\n",
       "  21294,\n",
       "  1053,\n",
       "  8935,\n",
       "  264,\n",
       "  2763,\n",
       "  505,\n",
       "  1317,\n",
       "  477,\n",
       "  24746,\n",
       "  2317,\n",
       "  11276,\n",
       "  13,\n",
       "  10541,\n",
       "  4724,\n",
       "  10756,\n",
       "  323,\n",
       "  57470,\n",
       "  649,\n",
       "  3493,\n",
       "  2680,\n",
       "  311,\n",
       "  264,\n",
       "  8294,\n",
       "  6677,\n",
       "  7463,\n",
       "  11,\n",
       "  872,\n",
       "  13340,\n",
       "  2410,\n",
       "  374,\n",
       "  539,\n",
       "  439,\n",
       "  8147,\n",
       "  439,\n",
       "  2539,\n",
       "  6666,\n",
       "  382,\n",
       "  198,\n",
       "  1163,\n",
       "  43470,\n",
       "  304,\n",
       "  1317,\n",
       "  9860,\n",
       "  9293,\n",
       "  323,\n",
       "  3465,\n",
       "  66266,\n",
       "  25,\n",
       "  28780,\n",
       "  927,\n",
       "  264,\n",
       "  35306,\n",
       "  3925,\n",
       "  323,\n",
       "  13750,\n",
       "  24919,\n",
       "  279,\n",
       "  6425,\n",
       "  3634,\n",
       "  7293,\n",
       "  17436,\n",
       "  13,\n",
       "  445,\n",
       "  11237,\n",
       "  82,\n",
       "  14993,\n",
       "  311,\n",
       "  7652,\n",
       "  6787,\n",
       "  994,\n",
       "  17011,\n",
       "  449,\n",
       "  16907,\n",
       "  6103,\n",
       "  11,\n",
       "  3339,\n",
       "  1124,\n",
       "  2753,\n",
       "  22514,\n",
       "  7863,\n",
       "  311,\n",
       "  12966,\n",
       "  889,\n",
       "  4048,\n",
       "  505,\n",
       "  9269,\n",
       "  323,\n",
       "  1493,\n",
       "  627,\n",
       "  198,\n",
       "  30035,\n",
       "  13,\n",
       "  220,\n",
       "  18,\n",
       "  13,\n",
       "  39154,\n",
       "  367,\n",
       "  315,\n",
       "  279,\n",
       "  94493,\n",
       "  290,\n",
       "  12914,\n",
       "  13,\n",
       "  320,\n",
       "  1945,\n",
       "  2592,\n",
       "  25,\n",
       "  1443,\n",
       "  6258,\n",
       "  612,\n",
       "  11868,\n",
       "  1003,\n",
       "  11,\n",
       "  220,\n",
       "  508,\n",
       "  1419,\n",
       "  8,\n",
       "  198,\n",
       "  791,\n",
       "  67709,\n",
       "  734,\n",
       "  27667,\n",
       "  994,\n",
       "  279,\n",
       "  35782,\n",
       "  374,\n",
       "  64481,\n",
       "  477,\n",
       "  5727,\n",
       "  59123,\n",
       "  2617,\n",
       "  323,\n",
       "  1288,\n",
       "  387,\n",
       "  10717,\n",
       "  13,\n",
       "  763,\n",
       "  43870,\n",
       "  9293,\n",
       "  19813,\n",
       "  311,\n",
       "  86648,\n",
       "  430,\n",
       "  1935,\n",
       "  2288,\n",
       "  1317,\n",
       "  2085,\n",
       "  2450,\n",
       "  13,\n",
       "  11166,\n",
       "  1791,\n",
       "  2617,\n",
       "  374,\n",
       "  4613,\n",
       "  439,\n",
       "  92372,\n",
       "  264,\n",
       "  8668,\n",
       "  315,\n",
       "  24871,\n",
       "  20086,\n",
       "  6299,\n",
       "  430,\n",
       "  3063,\n",
       "  311,\n",
       "  279,\n",
       "  1890,\n",
       "  22695,\n",
       "  304,\n",
       "  279,\n",
       "  4676,\n",
       "  13,\n",
       "  198,\n",
       "  12363,\n",
       "  44107,\n",
       "  1191,\n",
       "  374,\n",
       "  3549,\n",
       "  555,\n",
       "  9204,\n",
       "  1403,\n",
       "  64630,\n",
       "  10507,\n",
       "  311,\n",
       "  445,\n",
       "  11237,\n",
       "  323,\n",
       "  1855,\n",
       "  3187,\n",
       "  374,\n",
       "  264,\n",
       "  6857,\n",
       "  315,\n",
       "  320,\n",
       "  16479,\n",
       "  35782,\n",
       "  11,\n",
       "  10728,\n",
       "  22599,\n",
       "  369,\n",
       "  51346,\n",
       "  3938,\n",
       "  4442,\n",
       "  304,\n",
       "  279,\n",
       "  3197,\n",
       "  570,\n",
       "  5112,\n",
       "  63851,\n",
       "  527,\n",
       "  3779,\n",
       "  1139,\n",
       "  279,\n",
       "  8479,\n",
       "  753,\n",
       "  3318,\n",
       "  5044,\n",
       "  11,\n",
       "  709,\n",
       "  311,\n",
       "  2380,\n",
       "  11,\n",
       "  311,\n",
       "  387,\n",
       "  1511,\n",
       "  439,\n",
       "  2317,\n",
       "  369,\n",
       "  82198,\n",
       "  445,\n",
       "  11237,\n",
       "  13,\n",
       "  220,\n",
       "  198,\n",
       "  16533,\n",
       "  25,\n",
       "  128009,\n",
       "  128006,\n",
       "  78191,\n",
       "  128007,\n",
       "  198,\n",
       "  198,\n",
       "  6396,\n",
       "  97478,\n",
       "  3571,\n",
       "  374,\n",
       "  264,\n",
       "  15105,\n",
       "  430,\n",
       "  18808,\n",
       "  1523,\n",
       "  6485,\n",
       "  9256,\n",
       "  1139,\n",
       "  9333,\n",
       "  323,\n",
       "  35388,\n",
       "  7504,\n",
       "  11,\n",
       "  10923,\n",
       "  459,\n",
       "  8479,\n",
       "  477,\n",
       "  1646,\n",
       "  311,\n",
       "  3197,\n",
       "  8469,\n",
       "  323,\n",
       "  1304,\n",
       "  810,\n",
       "  71128,\n",
       "  11429,\n",
       "  13,\n",
       "  1115,\n",
       "  649,\n",
       "  387,\n",
       "  17427,\n",
       "  1555,\n",
       "  12823,\n",
       "  1778,\n",
       "  439,\n",
       "  29625,\n",
       "  315,\n",
       "  36287,\n",
       "  320,\n",
       "  7489,\n",
       "  51,\n",
       "  8,\n",
       "  477,\n",
       "  9119,\n",
       "  315,\n",
       "  61399,\n",
       "  11,\n",
       "  902,\n",
       "  21736,\n",
       "  29602,\n",
       "  8478,\n",
       "  5435,\n",
       "  1139,\n",
       "  5361,\n",
       "  3463,\n",
       "  7504,\n",
       "  323,\n",
       "  24038,\n",
       "  5361,\n",
       "  11555,\n",
       "  824,\n",
       "  3094,\n",
       "  13,\n",
       "  5546,\n",
       "  66266,\n",
       "  649,\n",
       "  1101,\n",
       "  387,\n",
       "  2884,\n",
       "  1555,\n",
       "  4382,\n",
       "  50745,\n",
       "  11,\n",
       "  3465,\n",
       "  19440,\n",
       "  11470,\n",
       "  11,\n",
       "  477,\n",
       "  3823,\n",
       "  11374,\n",
       "  13,\n",
       "  128009],\n",
       " 'total_duration': 20331432292,\n",
       " 'load_duration': 12852626667,\n",
       " 'prompt_eval_count': 636,\n",
       " 'prompt_eval_duration': 2815777000,\n",
       " 'eval_count': 86,\n",
       " 'eval_duration': 4658714000}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Generate a response using the Ollama model.\n",
    "model_name = 'llama3:8b-instruct-q8_0'\n",
    "ollama.generate(model=model_name, prompt=prompt_value.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
